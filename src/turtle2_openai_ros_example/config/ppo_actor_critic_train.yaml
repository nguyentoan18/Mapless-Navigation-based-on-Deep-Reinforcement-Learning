turtlebot2: #namespace

    #qlearn parameters
    
    alpha: 0.01 # Learning Rate
    alpha_decay: 0.01
    gamma: 1.0 # future rewards value 0 none 1 a lot
    epsilon: 1.0 # exploration, 0 none 1 a lot
    epsilon_decay: 0.995 # how we reduse the exploration
    epsilon_min: 0.01 # minimum value that epsilon can have
    batch_size: 64 # maximum size of the batches sampled from memory
    episodes_training: 10000
    episodes_running: 2000
    n_win_ticks: 80 # If the mean of rewards is bigger than this and have passed min_episodes, the task is considered finished
    min_episodes: 10
    #max_env_steps: None
    monitor: True
    quiet: False
    

    # Turtlebot Realated parameters


    number_splits: 10 #set to change the number of state splits for the continuous problem and also the number of env_variable splits

    running_step: 0.06 # Time for each step
    wait_time: 0.1 # Time to wait in the reset phases

    n_actions: 7 # We have 3 actions, Forwards,TurnLeft,TurnRight
    n_observations: 24 # We have 7 different observations

    speed_step: 1.0 # Time to wait in the reset phases

    linear_forward_speed: 1.5 # Spawned for ging fowards
    linear_turn_speed: 0.3 # Lienare speed when turning
    angular_speed: 0.5 # Angular speed when turning Left or Right
    init_linear_forward_speed: 0.0 # Initial linear speed in which we start each episode
    init_linear_turn_speed: 0.0 # Initial angular speed in shich we start each episode
    
    new_ranges: 20 # How many laser readings we jump in each observation reading, the bigger the less laser resolution
    min_range: 0.2 # Minimum meters below wich we consider we have crashed
    max_laser_value: 6.0 # Value considered Ok, no wall
    min_laser_value: 0.0 # Value considered there is an obstacle or crashed

    desired_pose:
      x: -3.5
      y: -3.0
      z: 0.0
    
    number_of_sectors: 3 # How many sectors we have
    middle_range: 1.0 # Minimum meters below wich we consider we have crashed
    danger_laser_value: 2 # Value considered Ok, no wall
    middle_laser_value: 1 # Middle value
    safe_laser_value: 0 # Value considered there is an obstacle or crashed
    
    forwards_reward: 5 # Points Given to go forwards
    turn_reward: 1 # Points Given to turn as action
    distance_reward: 15 # Points Given to turn as action
    end_episode_points: 200 # Points given when ending an episode
    
    desired_point_epsilon: 0.5
    max_distance_from_des_point: 30.0 # Maximum distance regitered in observations, has to be bigger than the largest distance of the workspace.
    number_decimals_precision_obs: 1
    
    
    done_reward: 1000.0 # reward
    closer_to_point_reward: 100.0 # reward



    gamma: 0.99
    update_interval: 5
    actor_lr: 0.0005
    critic_lr: 0.001
    clip_ratio: 0.1
    epochs: 3
    lmbda: 0.95
    batch_size: 64
    tau: 0.05
    train_start: 2000
    